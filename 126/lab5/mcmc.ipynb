{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"mcmc.ipynb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /opt/anaconda3/envs/eecs126/lib/python3.11/site-packages (from -r requirements.txt (line 1)) (2.2.2)\n",
      "Requirement already satisfied: matplotlib in /opt/anaconda3/envs/eecs126/lib/python3.11/site-packages (from -r requirements.txt (line 2)) (3.10.0)\n",
      "Requirement already satisfied: otter-grader==6.1.0 in /opt/anaconda3/envs/eecs126/lib/python3.11/site-packages (from -r requirements.txt (line 3)) (6.1.0)\n",
      "Requirement already satisfied: scipy~=1.15.0 in /opt/anaconda3/envs/eecs126/lib/python3.11/site-packages (from -r requirements.txt (line 4)) (1.15.2)\n",
      "Requirement already satisfied: click<9.0.0,>=8.1.7 in /opt/anaconda3/envs/eecs126/lib/python3.11/site-packages (from otter-grader==6.1.0->-r requirements.txt (line 3)) (8.1.8)\n",
      "Requirement already satisfied: dill>=0.3.0 in /opt/anaconda3/envs/eecs126/lib/python3.11/site-packages (from otter-grader==6.1.0->-r requirements.txt (line 3)) (0.3.9)\n",
      "Requirement already satisfied: fica>=0.4.1 in /opt/anaconda3/envs/eecs126/lib/python3.11/site-packages (from otter-grader==6.1.0->-r requirements.txt (line 3)) (0.4.1)\n",
      "Requirement already satisfied: ipylab<2.0.0,>=1.0.0 in /opt/anaconda3/envs/eecs126/lib/python3.11/site-packages (from otter-grader==6.1.0->-r requirements.txt (line 3)) (1.0.0)\n",
      "Requirement already satisfied: ipython in /opt/anaconda3/envs/eecs126/lib/python3.11/site-packages (from otter-grader==6.1.0->-r requirements.txt (line 3)) (8.30.0)\n",
      "Requirement already satisfied: ipywidgets<9.0.0,>=8.1.5 in /opt/anaconda3/envs/eecs126/lib/python3.11/site-packages (from otter-grader==6.1.0->-r requirements.txt (line 3)) (8.1.5)\n",
      "Requirement already satisfied: jinja2<4.0,>=3.1 in /opt/anaconda3/envs/eecs126/lib/python3.11/site-packages (from otter-grader==6.1.0->-r requirements.txt (line 3)) (3.1.5)\n",
      "Requirement already satisfied: jupytext<2.0.0,>=1.16.4 in /opt/anaconda3/envs/eecs126/lib/python3.11/site-packages (from otter-grader==6.1.0->-r requirements.txt (line 3)) (1.16.6)\n",
      "Requirement already satisfied: nbconvert>=6.0.0 in /opt/anaconda3/envs/eecs126/lib/python3.11/site-packages (from nbconvert[webpdf]>=6.0.0; sys_platform != \"emscripten\" and sys_platform != \"wasi\"->otter-grader==6.1.0->-r requirements.txt (line 3)) (7.16.4)\n",
      "Requirement already satisfied: nbformat>=5.0.0 in /opt/anaconda3/envs/eecs126/lib/python3.11/site-packages (from otter-grader==6.1.0->-r requirements.txt (line 3)) (5.10.4)\n",
      "Requirement already satisfied: pandas>=2.0.0 in /opt/anaconda3/envs/eecs126/lib/python3.11/site-packages (from otter-grader==6.1.0->-r requirements.txt (line 3)) (2.2.3)\n",
      "Requirement already satisfied: python-on-whales<1.0.0,>=0.72.0 in /opt/anaconda3/envs/eecs126/lib/python3.11/site-packages (from otter-grader==6.1.0->-r requirements.txt (line 3)) (0.75.1)\n",
      "Requirement already satisfied: pyyaml<7,>=6 in /opt/anaconda3/envs/eecs126/lib/python3.11/site-packages (from otter-grader==6.1.0->-r requirements.txt (line 3)) (6.0.2)\n",
      "Requirement already satisfied: requests<3.0,>=2.31 in /opt/anaconda3/envs/eecs126/lib/python3.11/site-packages (from otter-grader==6.1.0->-r requirements.txt (line 3)) (2.32.3)\n",
      "Requirement already satisfied: wrapt<2.0.0,>=1.16.0 in /opt/anaconda3/envs/eecs126/lib/python3.11/site-packages (from otter-grader==6.1.0->-r requirements.txt (line 3)) (1.17.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/anaconda3/envs/eecs126/lib/python3.11/site-packages (from matplotlib->-r requirements.txt (line 2)) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/anaconda3/envs/eecs126/lib/python3.11/site-packages (from matplotlib->-r requirements.txt (line 2)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/anaconda3/envs/eecs126/lib/python3.11/site-packages (from matplotlib->-r requirements.txt (line 2)) (4.55.8)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/anaconda3/envs/eecs126/lib/python3.11/site-packages (from matplotlib->-r requirements.txt (line 2)) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/envs/eecs126/lib/python3.11/site-packages (from matplotlib->-r requirements.txt (line 2)) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in /opt/anaconda3/envs/eecs126/lib/python3.11/site-packages (from matplotlib->-r requirements.txt (line 2)) (11.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/anaconda3/envs/eecs126/lib/python3.11/site-packages (from matplotlib->-r requirements.txt (line 2)) (3.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/anaconda3/envs/eecs126/lib/python3.11/site-packages (from matplotlib->-r requirements.txt (line 2)) (2.9.0.post0)\n",
      "Requirement already satisfied: docutils in /opt/anaconda3/envs/eecs126/lib/python3.11/site-packages (from fica>=0.4.1->otter-grader==6.1.0->-r requirements.txt (line 3)) (0.21.2)\n",
      "Requirement already satisfied: sphinx in /opt/anaconda3/envs/eecs126/lib/python3.11/site-packages (from fica>=0.4.1->otter-grader==6.1.0->-r requirements.txt (line 3)) (8.1.3)\n",
      "Requirement already satisfied: comm>=0.1.3 in /opt/anaconda3/envs/eecs126/lib/python3.11/site-packages (from ipywidgets<9.0.0,>=8.1.5->otter-grader==6.1.0->-r requirements.txt (line 3)) (0.2.1)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /opt/anaconda3/envs/eecs126/lib/python3.11/site-packages (from ipywidgets<9.0.0,>=8.1.5->otter-grader==6.1.0->-r requirements.txt (line 3)) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.12 in /opt/anaconda3/envs/eecs126/lib/python3.11/site-packages (from ipywidgets<9.0.0,>=8.1.5->otter-grader==6.1.0->-r requirements.txt (line 3)) (4.0.13)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.12 in /opt/anaconda3/envs/eecs126/lib/python3.11/site-packages (from ipywidgets<9.0.0,>=8.1.5->otter-grader==6.1.0->-r requirements.txt (line 3)) (3.0.13)\n",
      "Requirement already satisfied: decorator in /opt/anaconda3/envs/eecs126/lib/python3.11/site-packages (from ipython->otter-grader==6.1.0->-r requirements.txt (line 3)) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/anaconda3/envs/eecs126/lib/python3.11/site-packages (from ipython->otter-grader==6.1.0->-r requirements.txt (line 3)) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in /opt/anaconda3/envs/eecs126/lib/python3.11/site-packages (from ipython->otter-grader==6.1.0->-r requirements.txt (line 3)) (0.1.6)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in /opt/anaconda3/envs/eecs126/lib/python3.11/site-packages (from ipython->otter-grader==6.1.0->-r requirements.txt (line 3)) (3.0.43)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /opt/anaconda3/envs/eecs126/lib/python3.11/site-packages (from ipython->otter-grader==6.1.0->-r requirements.txt (line 3)) (2.19.1)\n",
      "Requirement already satisfied: stack-data in /opt/anaconda3/envs/eecs126/lib/python3.11/site-packages (from ipython->otter-grader==6.1.0->-r requirements.txt (line 3)) (0.2.0)\n",
      "Requirement already satisfied: typing-extensions>=4.6 in /opt/anaconda3/envs/eecs126/lib/python3.11/site-packages (from ipython->otter-grader==6.1.0->-r requirements.txt (line 3)) (4.12.2)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/anaconda3/envs/eecs126/lib/python3.11/site-packages (from ipython->otter-grader==6.1.0->-r requirements.txt (line 3)) (4.8.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/envs/eecs126/lib/python3.11/site-packages (from jinja2<4.0,>=3.1->otter-grader==6.1.0->-r requirements.txt (line 3)) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=1.0 in /opt/anaconda3/envs/eecs126/lib/python3.11/site-packages (from jupytext<2.0.0,>=1.16.4->otter-grader==6.1.0->-r requirements.txt (line 3)) (3.0.0)\n",
      "Requirement already satisfied: mdit-py-plugins in /opt/anaconda3/envs/eecs126/lib/python3.11/site-packages (from jupytext<2.0.0,>=1.16.4->otter-grader==6.1.0->-r requirements.txt (line 3)) (0.4.2)\n",
      "Requirement already satisfied: beautifulsoup4 in /opt/anaconda3/envs/eecs126/lib/python3.11/site-packages (from nbconvert>=6.0.0->nbconvert[webpdf]>=6.0.0; sys_platform != \"emscripten\" and sys_platform != \"wasi\"->otter-grader==6.1.0->-r requirements.txt (line 3)) (4.12.3)\n",
      "Requirement already satisfied: bleach!=5.0.0 in /opt/anaconda3/envs/eecs126/lib/python3.11/site-packages (from nbconvert>=6.0.0->nbconvert[webpdf]>=6.0.0; sys_platform != \"emscripten\" and sys_platform != \"wasi\"->otter-grader==6.1.0->-r requirements.txt (line 3)) (6.2.0)\n",
      "Requirement already satisfied: defusedxml in /opt/anaconda3/envs/eecs126/lib/python3.11/site-packages (from nbconvert>=6.0.0->nbconvert[webpdf]>=6.0.0; sys_platform != \"emscripten\" and sys_platform != \"wasi\"->otter-grader==6.1.0->-r requirements.txt (line 3)) (0.7.1)\n",
      "Requirement already satisfied: jupyter-core>=4.7 in /opt/anaconda3/envs/eecs126/lib/python3.11/site-packages (from nbconvert>=6.0.0->nbconvert[webpdf]>=6.0.0; sys_platform != \"emscripten\" and sys_platform != \"wasi\"->otter-grader==6.1.0->-r requirements.txt (line 3)) (5.7.2)\n",
      "Requirement already satisfied: jupyterlab-pygments in /opt/anaconda3/envs/eecs126/lib/python3.11/site-packages (from nbconvert>=6.0.0->nbconvert[webpdf]>=6.0.0; sys_platform != \"emscripten\" and sys_platform != \"wasi\"->otter-grader==6.1.0->-r requirements.txt (line 3)) (0.1.2)\n",
      "Requirement already satisfied: mistune<4,>=2.0.3 in /opt/anaconda3/envs/eecs126/lib/python3.11/site-packages (from nbconvert>=6.0.0->nbconvert[webpdf]>=6.0.0; sys_platform != \"emscripten\" and sys_platform != \"wasi\"->otter-grader==6.1.0->-r requirements.txt (line 3)) (2.0.4)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in /opt/anaconda3/envs/eecs126/lib/python3.11/site-packages (from nbconvert>=6.0.0->nbconvert[webpdf]>=6.0.0; sys_platform != \"emscripten\" and sys_platform != \"wasi\"->otter-grader==6.1.0->-r requirements.txt (line 3)) (0.8.0)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /opt/anaconda3/envs/eecs126/lib/python3.11/site-packages (from nbconvert>=6.0.0->nbconvert[webpdf]>=6.0.0; sys_platform != \"emscripten\" and sys_platform != \"wasi\"->otter-grader==6.1.0->-r requirements.txt (line 3)) (1.5.0)\n",
      "Requirement already satisfied: tinycss2 in /opt/anaconda3/envs/eecs126/lib/python3.11/site-packages (from nbconvert>=6.0.0->nbconvert[webpdf]>=6.0.0; sys_platform != \"emscripten\" and sys_platform != \"wasi\"->otter-grader==6.1.0->-r requirements.txt (line 3)) (1.4.0)\n",
      "Requirement already satisfied: playwright in /opt/anaconda3/envs/eecs126/lib/python3.11/site-packages (from nbconvert[webpdf]>=6.0.0; sys_platform != \"emscripten\" and sys_platform != \"wasi\"->otter-grader==6.1.0->-r requirements.txt (line 3)) (1.50.0)\n",
      "Requirement already satisfied: fastjsonschema>=2.15 in /opt/anaconda3/envs/eecs126/lib/python3.11/site-packages (from nbformat>=5.0.0->otter-grader==6.1.0->-r requirements.txt (line 3)) (2.20.0)\n",
      "Requirement already satisfied: jsonschema>=2.6 in /opt/anaconda3/envs/eecs126/lib/python3.11/site-packages (from nbformat>=5.0.0->otter-grader==6.1.0->-r requirements.txt (line 3)) (4.23.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/envs/eecs126/lib/python3.11/site-packages (from pandas>=2.0.0->otter-grader==6.1.0->-r requirements.txt (line 3)) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/envs/eecs126/lib/python3.11/site-packages (from pandas>=2.0.0->otter-grader==6.1.0->-r requirements.txt (line 3)) (2025.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/envs/eecs126/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib->-r requirements.txt (line 2)) (1.16.0)\n",
      "Requirement already satisfied: pydantic!=2.0.*,<3,>=2 in /opt/anaconda3/envs/eecs126/lib/python3.11/site-packages (from python-on-whales<1.0.0,>=0.72.0->otter-grader==6.1.0->-r requirements.txt (line 3)) (2.10.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/envs/eecs126/lib/python3.11/site-packages (from requests<3.0,>=2.31->otter-grader==6.1.0->-r requirements.txt (line 3)) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/envs/eecs126/lib/python3.11/site-packages (from requests<3.0,>=2.31->otter-grader==6.1.0->-r requirements.txt (line 3)) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/envs/eecs126/lib/python3.11/site-packages (from requests<3.0,>=2.31->otter-grader==6.1.0->-r requirements.txt (line 3)) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/envs/eecs126/lib/python3.11/site-packages (from requests<3.0,>=2.31->otter-grader==6.1.0->-r requirements.txt (line 3)) (2025.1.31)\n",
      "Requirement already satisfied: webencodings in /opt/anaconda3/envs/eecs126/lib/python3.11/site-packages (from bleach!=5.0.0->nbconvert>=6.0.0->nbconvert[webpdf]>=6.0.0; sys_platform != \"emscripten\" and sys_platform != \"wasi\"->otter-grader==6.1.0->-r requirements.txt (line 3)) (0.5.1)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /opt/anaconda3/envs/eecs126/lib/python3.11/site-packages (from jedi>=0.16->ipython->otter-grader==6.1.0->-r requirements.txt (line 3)) (0.8.4)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /opt/anaconda3/envs/eecs126/lib/python3.11/site-packages (from jsonschema>=2.6->nbformat>=5.0.0->otter-grader==6.1.0->-r requirements.txt (line 3)) (24.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/anaconda3/envs/eecs126/lib/python3.11/site-packages (from jsonschema>=2.6->nbformat>=5.0.0->otter-grader==6.1.0->-r requirements.txt (line 3)) (2023.7.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /opt/anaconda3/envs/eecs126/lib/python3.11/site-packages (from jsonschema>=2.6->nbformat>=5.0.0->otter-grader==6.1.0->-r requirements.txt (line 3)) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /opt/anaconda3/envs/eecs126/lib/python3.11/site-packages (from jsonschema>=2.6->nbformat>=5.0.0->otter-grader==6.1.0->-r requirements.txt (line 3)) (0.22.3)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /opt/anaconda3/envs/eecs126/lib/python3.11/site-packages (from jupyter-core>=4.7->nbconvert>=6.0.0->nbconvert[webpdf]>=6.0.0; sys_platform != \"emscripten\" and sys_platform != \"wasi\"->otter-grader==6.1.0->-r requirements.txt (line 3)) (3.10.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/anaconda3/envs/eecs126/lib/python3.11/site-packages (from markdown-it-py>=1.0->jupytext<2.0.0,>=1.16.4->otter-grader==6.1.0->-r requirements.txt (line 3)) (0.1.2)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in /opt/anaconda3/envs/eecs126/lib/python3.11/site-packages (from nbclient>=0.5.0->nbconvert>=6.0.0->nbconvert[webpdf]>=6.0.0; sys_platform != \"emscripten\" and sys_platform != \"wasi\"->otter-grader==6.1.0->-r requirements.txt (line 3)) (8.6.3)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/anaconda3/envs/eecs126/lib/python3.11/site-packages (from pexpect>4.3->ipython->otter-grader==6.1.0->-r requirements.txt (line 3)) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /opt/anaconda3/envs/eecs126/lib/python3.11/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython->otter-grader==6.1.0->-r requirements.txt (line 3)) (0.2.5)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/anaconda3/envs/eecs126/lib/python3.11/site-packages (from pydantic!=2.0.*,<3,>=2->python-on-whales<1.0.0,>=0.72.0->otter-grader==6.1.0->-r requirements.txt (line 3)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /opt/anaconda3/envs/eecs126/lib/python3.11/site-packages (from pydantic!=2.0.*,<3,>=2->python-on-whales<1.0.0,>=0.72.0->otter-grader==6.1.0->-r requirements.txt (line 3)) (2.27.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/anaconda3/envs/eecs126/lib/python3.11/site-packages (from beautifulsoup4->nbconvert>=6.0.0->nbconvert[webpdf]>=6.0.0; sys_platform != \"emscripten\" and sys_platform != \"wasi\"->otter-grader==6.1.0->-r requirements.txt (line 3)) (2.5)\n",
      "Requirement already satisfied: pyee<13,>=12 in /opt/anaconda3/envs/eecs126/lib/python3.11/site-packages (from playwright->nbconvert[webpdf]>=6.0.0; sys_platform != \"emscripten\" and sys_platform != \"wasi\"->otter-grader==6.1.0->-r requirements.txt (line 3)) (12.1.1)\n",
      "Requirement already satisfied: greenlet<4.0.0,>=3.1.1 in /opt/anaconda3/envs/eecs126/lib/python3.11/site-packages (from playwright->nbconvert[webpdf]>=6.0.0; sys_platform != \"emscripten\" and sys_platform != \"wasi\"->otter-grader==6.1.0->-r requirements.txt (line 3)) (3.1.1)\n",
      "Requirement already satisfied: sphinxcontrib-applehelp>=1.0.7 in /opt/anaconda3/envs/eecs126/lib/python3.11/site-packages (from sphinx->fica>=0.4.1->otter-grader==6.1.0->-r requirements.txt (line 3)) (2.0.0)\n",
      "Requirement already satisfied: sphinxcontrib-devhelp>=1.0.6 in /opt/anaconda3/envs/eecs126/lib/python3.11/site-packages (from sphinx->fica>=0.4.1->otter-grader==6.1.0->-r requirements.txt (line 3)) (2.0.0)\n",
      "Requirement already satisfied: sphinxcontrib-htmlhelp>=2.0.6 in /opt/anaconda3/envs/eecs126/lib/python3.11/site-packages (from sphinx->fica>=0.4.1->otter-grader==6.1.0->-r requirements.txt (line 3)) (2.1.0)\n",
      "Requirement already satisfied: sphinxcontrib-jsmath>=1.0.1 in /opt/anaconda3/envs/eecs126/lib/python3.11/site-packages (from sphinx->fica>=0.4.1->otter-grader==6.1.0->-r requirements.txt (line 3)) (1.0.1)\n",
      "Requirement already satisfied: sphinxcontrib-qthelp>=1.0.6 in /opt/anaconda3/envs/eecs126/lib/python3.11/site-packages (from sphinx->fica>=0.4.1->otter-grader==6.1.0->-r requirements.txt (line 3)) (2.0.0)\n",
      "Requirement already satisfied: sphinxcontrib-serializinghtml>=1.1.9 in /opt/anaconda3/envs/eecs126/lib/python3.11/site-packages (from sphinx->fica>=0.4.1->otter-grader==6.1.0->-r requirements.txt (line 3)) (2.0.0)\n",
      "Requirement already satisfied: snowballstemmer>=2.2 in /opt/anaconda3/envs/eecs126/lib/python3.11/site-packages (from sphinx->fica>=0.4.1->otter-grader==6.1.0->-r requirements.txt (line 3)) (2.2.0)\n",
      "Requirement already satisfied: babel>=2.13 in /opt/anaconda3/envs/eecs126/lib/python3.11/site-packages (from sphinx->fica>=0.4.1->otter-grader==6.1.0->-r requirements.txt (line 3)) (2.16.0)\n",
      "Requirement already satisfied: alabaster>=0.7.14 in /opt/anaconda3/envs/eecs126/lib/python3.11/site-packages (from sphinx->fica>=0.4.1->otter-grader==6.1.0->-r requirements.txt (line 3)) (1.0.0)\n",
      "Requirement already satisfied: imagesize>=1.3 in /opt/anaconda3/envs/eecs126/lib/python3.11/site-packages (from sphinx->fica>=0.4.1->otter-grader==6.1.0->-r requirements.txt (line 3)) (1.4.1)\n",
      "Requirement already satisfied: executing in /opt/anaconda3/envs/eecs126/lib/python3.11/site-packages (from stack-data->ipython->otter-grader==6.1.0->-r requirements.txt (line 3)) (0.8.3)\n",
      "Requirement already satisfied: asttokens in /opt/anaconda3/envs/eecs126/lib/python3.11/site-packages (from stack-data->ipython->otter-grader==6.1.0->-r requirements.txt (line 3)) (2.0.5)\n",
      "Requirement already satisfied: pure-eval in /opt/anaconda3/envs/eecs126/lib/python3.11/site-packages (from stack-data->ipython->otter-grader==6.1.0->-r requirements.txt (line 3)) (0.2.2)\n",
      "Requirement already satisfied: pyzmq>=23.0 in /opt/anaconda3/envs/eecs126/lib/python3.11/site-packages (from jupyter-client>=6.1.12->nbclient>=0.5.0->nbconvert>=6.0.0->nbconvert[webpdf]>=6.0.0; sys_platform != \"emscripten\" and sys_platform != \"wasi\"->otter-grader==6.1.0->-r requirements.txt (line 3)) (26.2.0)\n",
      "Requirement already satisfied: tornado>=6.2 in /opt/anaconda3/envs/eecs126/lib/python3.11/site-packages (from jupyter-client>=6.1.12->nbclient>=0.5.0->nbconvert>=6.0.0->nbconvert[webpdf]>=6.0.0; sys_platform != \"emscripten\" and sys_platform != \"wasi\"->otter-grader==6.1.0->-r requirements.txt (line 3)) (6.4.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# If modules have not been installed yet:\n",
    "%pip install -r requirements.txt\n",
    "\n",
    "# Restart kernel afterwards, if needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Markov Chain Monte Carlo and Applications\n",
    "\n",
    "v1.0 (2018 Spring) Tavor Baharav, Kaylee Burns, Gary Cheng, Sinho Chewi, Hemang Jangle, William Gan, Alvin Kao, Chen Meng, Vrettos Muolos, Kanaad Parvate, Ray Ramamurti, Kannan Ramchandran\n",
    "\n",
    "v1.1 (2019 Fall) William Gan, Justin Hong, Raghav Anand, Alex Li, Katie Kang, Eric Liu, Aditya Mishra, Kevin Lu, Michael Whitmeyer, Sean Meng, Alan He, Nikita Dhawan, Tae Hyung Kim, Shyam Parekh\n",
    "\n",
    "v1.2 (2022 Fall) Tweaks by Axel Li\n",
    "\n",
    "v1.3 (2023 Spring) Tweaks by Reina Wang\n",
    "\n",
    "v1.4 (2024 Fall) Tweaks by Tianhao Wu\n",
    "\n",
    "v1.5 (2025 Spring) Lance Mathias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Markov Chain Monte Carlo methods are a powerful collection of techniques that allow us to sample from a distribution _even if we can't calculate the distribution directly._ This is useful for complex models, whose distributions may be intractable to compute. The idea is that, if we are able to sample from our desired distribution, we can answer any questions we may have about that distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is MCMC?\n",
    "\n",
    "Our goal is to simulate a Markov chain with a state for each outcome in our probability space. If the stationary distribution of the chain matches the distribution we want to sample from, then a random walk on the chain should perform like a sequence of samples from our desired distribution.\n",
    "\n",
    "In this lab we will be focusing on the Metropolis-Hastings algorithm, but this is not the only kind of MCMC method. Gibbs sampling, which you may have encountered in CS 188, is also a MCMC method. Gibbs sampling, however, requires computing a conditional distribution for each random variable in your model, which can be impractical and inefficient for some problems.\n",
    "\n",
    "We'll also explore an application of our algorithm to a sneaky spy challenge: use Metropolis-Hastings to decode the secret messages Gary is sending to Tavor! ðŸ•µï¸"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Developing Metropolis Hastings (MH)\n",
    "\n",
    "Our task is to define a set of transition and acceptance probabilities so that we have an aperiodic Markov Chain whose stationary distribution $\\pi(x)$ is equal to our target distribution $P(x)$. The MH algorithm does this implicitly by defining a procedure for transitioning between states. However, it has some assumptions. In particular, it assumes that you can compute:\n",
    "\n",
    "- $f(x)$, **a directly proportional estimate** of $P(x)$, i.e. $P(x) = \\frac{f(x)}{\\sum_{y \\in \\mathcal{X}} f(y)}$.\n",
    "- $g(x, \\cdot)$, a proposal distribution for the next state, where $x$ is your current state.\n",
    "\n",
    "The MH algorithm says, at each time step:\n",
    "\n",
    "- Propose the next candidate state $y$ according $g(x,\\cdot)$.\n",
    "- Accept $y$, with probability $A(x,y) = min\\{1, \\frac{f(y)g(y,x)}{f(x)g(x,y)}\\}$.\n",
    "- If you accept the proposal, transition to $y$. Otherwise, stay in $x$.\n",
    "\n",
    "Following this procedure, the stationary distribution of the implicitly defined Markov Chain will be $P(x)$. Thus you can take a random walk to sample from $P(x)$. However, in practice, the following two extensions are made:\n",
    "\n",
    "- Taking every step-th state in the random walk. This helps reduce the dependence between samples.\n",
    "- Letting the chain walk a bit so that the distribution can converge to the stationary distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a bit of setup\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "\n",
    "#######################################\n",
    "###   PDFs of three distributions   ###\n",
    "#######################################\n",
    "\n",
    "def normal(mu,sigma):\n",
    "    return lambda x: stats.norm.pdf(x,loc = mu, scale = sigma)\n",
    "\n",
    "def exponential(lam):\n",
    "    return lambda x: lam*math.exp(-lam*x) if x >=0 else 0\n",
    "\n",
    "def gauss_mix(p,mu1,sig1,mu2,sig2):\n",
    "    \"\"\"\n",
    "    Gaussian mixture with probabilities of selection being p and 1-p for N(mu1,sig1) and N(mu2,sig2) respectively\n",
    "    \"\"\"\n",
    "\n",
    "    return lambda x: p*stats.norm.pdf(x,loc = mu1, scale = sig1) + (1-p)*stats.norm.pdf(x, loc = mu2, scale = sig2)\n",
    "\n",
    "#######################################\n",
    "###   Plotting and Graping Utils    ###\n",
    "#######################################\n",
    "\n",
    "def plot_transitions(samples, figname=None):\n",
    "    plt.plot([i for i in range(len(samples))], samples)\n",
    "    if figname:\n",
    "        plt.title(figname)\n",
    "    plt.show()\n",
    "\n",
    "def plot_histogram_and_transitions(samples, figname=[]):\n",
    "    plt.hist(samples)\n",
    "    if isinstance(figname, list) and len(figname) == 2:\n",
    "        plt.title(figname[0])\n",
    "    plt.show()\n",
    "    plot_transitions(samples, figname[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metropolis-Hastings Implementation\n",
    "\n",
    "In the cell below, implement Metropolis-Hastings according to the doc string. It should work for generic proposal, acceptance, and intitialization functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "def metropolis_hastings(proposal_func, init_func, score_func,\n",
    "                        num_iters, step=30):\n",
    "    \"\"\"\n",
    "    Runs the metropolis-hastings algorithm for\n",
    "    num_iters iterations, using proposal_func\n",
    "    to generate candidate states and scorer to\n",
    "    assign probability scores to candidate\n",
    "    states.\n",
    "    \n",
    "    proposal_func: function that proposes\n",
    "        candidate state; takes in current state as\n",
    "        argument and returns candidate state\n",
    "    init_func: function that proposes starting\n",
    "        state; takes no arguments and returns a\n",
    "        sample state\n",
    "    score_func: function that calculates f(y)/f(x)\n",
    "        * g(y,x)/g(x,y); takes in two state samples\n",
    "        (the current sample x then the candidate y).\n",
    "    \n",
    "    Returns a sequence of every step-th sample. You \n",
    "    should sample regardless of whether a transition \n",
    "    occurs. The length of the final sequence should \n",
    "    be num_iters // step.\n",
    "    \"\"\"\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"metropolis_hastings_implementation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling from Distributions Using MH\n",
    "\n",
    "Now that we have a method for sampling from distributions, let's apply it to some models. We'll start with very simple models so that we can compare the results from sampling with what we can compute analytically. This is also a useful opportunity for you to debug your implementation. Your implementation should be able to model a Gaussian and exponential distribution successfully.\n",
    "\n",
    "*Note: Our proposal distribution will be a normal distribution centered around our current state for the purposes of this lab. Take this into account when analyzing these examples.*\n",
    "\n",
    "*An interesting fact to note is that the algorithm works even for these **continuous distributions**. In this case the underlying Markov Chain will have a continuous state space ($\\mathbb{R}$)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Friendly Gaussian: $\\mathcal{N}(60, 1)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_prior = lambda: np.random.normal(loc=60)\n",
    "sample_candidate = lambda theta: np.random.normal(loc=theta)\n",
    "scorer = lambda x, y: (math.exp(-((y - 60)**2)/2)) / (math.exp(-((x - 60)**2)/2))\n",
    "normal_samples = metropolis_hastings(sample_candidate, sample_prior, scorer, 10000)\n",
    "plot_histogram_and_transitions(normal_samples, ['Fig 1.1: $\\mathcal{N}(60, 1)$ Samples', 'Fig 1.2: $\\mathcal{N}(60, 1)$ Transitions'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exponential Distribution: $\\text{Exponential}(0.5)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_pdf = exponential(0.5)\n",
    "exp_scorer = lambda x,y: exp_pdf(y) / exp_pdf(x)\n",
    "exp_prior = lambda : 10\n",
    "exp_samples = metropolis_hastings(sample_candidate, exp_prior, exp_scorer, 10000)\n",
    "plot_histogram_and_transitions(exp_samples, ['Fig 1.3: $\\\\text{Exponential}(0.5)$ Samples', 'Fig 1.4: $\\\\text{Exponential}(0.5)$ Transitions'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Effects of Initial Distribution, Convergence Diagnosis and Burn-in Time\n",
    "In the case of the Gaussian above, our `init_function`(initial distribution) was $\\mathcal{N}(60,1)$ which is exactly the same as the distribution we were trying to sample, i.e, we started the chain from the stationary distribution. However in general, we obviously don't have the ability to sample from the distribution we were trying to sample from in the first place! Notice that in the exponential, it goes down drastically from 10 where we started the chain, and oscillates more around lower values.\n",
    "\n",
    "Now run the following code, and answer the questions below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_prior = lambda: np.random.normal(loc=1000)\n",
    "sample_candidate = lambda theta: np.random.normal(loc=theta, scale=3)\n",
    "normal_pdf = normal(60,30)\n",
    "scorer = lambda x, y: normal_pdf(y) / normal_pdf(x)\n",
    "normal_samples = metropolis_hastings(sample_candidate, sample_prior, scorer, 5000, 1)\n",
    "plot_transitions(normal_samples, 'Fig 3.1: $\\mathcal{N}(60, 30)$ Samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_prior = lambda: np.random.normal(loc=75)\n",
    "sample_candidate = lambda theta: np.random.normal(loc=theta, scale=0.1)\n",
    "normal_pdf = normal(60,1)\n",
    "scorer = lambda x, y: normal_pdf(y) / normal_pdf(x)\n",
    "normal_samples = metropolis_hastings(sample_candidate, sample_prior, scorer, 5000, 1)\n",
    "plot_transitions(normal_samples, 'Fig 3.2: $\\mathcal{N}(60, 1)$ Samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "**Question 1:** In the last trials we ran, are there some samples we need to ignore at the beginning? Explain what is happening with the Markov Chain based on the parameters we've used and your observations from the state vs. iteration plot.\n",
    "\n",
    "Examining Figures 2.1 and 2.2, tell us approximately how many samples we need to ignore (or 0 if we don't need to ignore any samples). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "source": [
    "Feel free to use this space to draft your answer. When you finish, remember to paste your response and any relevant plots/figures **into the accompanying Gradescope assignment**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "## Drawbacks of MCMC Techniques\n",
    "\n",
    "Now we'll evaluate the effectiveness of our sampling technique on a variety of models. The examples below will highlight some of the drawbacks and idiosyncrasies of MCMC techniques. We will look at this in the context of distributions with two peaks (two separated regions of high probability), also known as bimodal distributions. We will see that the peaks may not be sampled appropriately.\n",
    "\n",
    "## Bimodal Mixture of Gaussians\n",
    "\n",
    "A mixture of Gaussians is obtained when you have two subpopulations ('classes') each distributed normally($\\mathcal{N}(\\mu_1,\\sigma_1^2)$ and $\\mathcal{N}(\\mu_2,\\sigma_2^2)$) . An example is heights of people with the subclasses of men and women. In the mixture model the 'classes' have probabilities $p$ and $1-p$ respectively. So the pdf of this distribution would be \n",
    "$$\n",
    "p \\cdot f_X(x\\ |\\text{ class 1}) + (1-p)\\cdot f_X(x\\ |\\text{ class 2}) = p\\cdot \\frac{1}{\\sqrt{2\\pi \\sigma_1^2}} \\cdot \\exp \\left( {-\\frac{(x - \\mu_1)^2}{2\\sigma_1^2}} \\right) + \\left(1-p\\right) \\cdot \\frac{1}{\\sqrt{2\\pi \\sigma_2^2}} \\cdot \\exp \\left({-\\frac{(x - \\mu_2)^2}{2\\sigma_2^2}} \\right)\n",
    "$$\n",
    "\n",
    "For there to be two peaks in the pdf (to be bimodal), there should be (loosely speaking) sufficient separation between the means with respect to the standard deviations(the widths of the distributions). Otherwise if the peaks are too close relative to the widths, it is possible for the mixture to lead to just one central peak between the two means. There are exact conditions for this you can look up if you are interested. \n",
    "\n",
    "For this part we will be using a mixture with equal probabilities $(0.5)$ on each of the individual Gaussians with means $60$ and $40$. Try MH on this distribution for standard deviations of $5,3,1$ for each of the individual Gaussians. You should see that one of the peaks dominates (could be either one) as the standard deviation reduces even though both classes have an equal probability. For low std devs 2 and 1, only one peak should show up. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_from_bimodal(stdev):\n",
    "    \"\"\"Samples from bimodal mixture of Gaussians\n",
    "    with standard deviation stdev, as described above.\"\"\"\n",
    "    \n",
    "    pdf = gauss_mix(0.5,40,stdev,60,stdev)\n",
    "\n",
    "    sample_candidate = lambda theta: np.random.normal(loc=theta)\n",
    "    new_scorer = lambda x,y: pdf(y)/pdf(x) \n",
    "    new_prior = lambda : 50\n",
    "\n",
    "    points = metropolis_hastings(sample_candidate, new_prior, new_scorer, 10000)\n",
    "    plot_histogram_and_transitions(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_from_bimodal(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_from_bimodal(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_from_bimodal(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What effect do you think changing the standard deviation has? What possible disadvantage of MH does this bimodal distribution show?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "What effect do you think changing the standard deviation has? What possible disadvantage of MH does this bimodal distribution show?\n",
    "\n",
    "Answer the following questions on the corresponding Gradescope assignment:\n",
    "\n",
    "**Question 2:** What happens to the jumps in the transition plots as the standard deviation decreases?\n",
    "    \n",
    "- The jumps become more frequent\n",
    "- The jumps become less frequent\n",
    "- The jumps stay the same\n",
    "- There are no jumps in the transition plots\n",
    "\n",
    "**Question 3:** As the standard deviation decreases, what happens to the likelihood of proposing a state on the other peak with high probability?\n",
    "    \n",
    "- It increases\n",
    "- It decreases\n",
    "- It remains the same\n",
    "- It becomes zero\n",
    "\n",
    "**Question 4:** What is a disadvantage of MH for bimodal distributions?\n",
    "    \n",
    "- It always samples from only one peak\n",
    "- It requires too many iterations to converge\n",
    "- It's difficult to determine the number of iterations needed to sample both peaks evenly\n",
    "- It cannot handle bimodal distributions at all\n",
    "\n",
    "**Question 5:** How does decreasing the standard deviation affect the separation between high probability regions?\n",
    "    \n",
    "- It increases the separation\n",
    "- It decreases the separation\n",
    "- It has no effect on the separation\n",
    "- It eliminates one of the high probability regions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "source": [
    "Feel free to use this space to draft your answer. When you finish, remember to paste your response and any relevant plots/figures **into the accompanying Gradescope assignment**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "## Decoding Secret Messages Using MCMC (4 points)\n",
    "\n",
    "Now we'll use our algorithm to solve a mystery on the EE 126 staff. Grumpy Gary and Tricky Tavor are sending each other secret messages using a cipher: each character in the message is either an uppercase letter or a space (denoted `_` ) (so there are 27 possible characters). Their cipher permutes the alphabet -- every character maps to another character (or possibly itself), and no two characters map to the same thing. To send a message, they replace each character with the corresponding character in their cipher.\n",
    "\n",
    "For example, if their cipher was the following:\n",
    "\n",
    "| A | B | C | D | E | F | G | H | I | J | K | L | M | N | O | P | Q | R | S | T | U | V | W | X | Y | Z | _ |\n",
    "|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
    "| X | T | A | G | M | L | C | Q | P | Z | H | W | J | I | E | B | K | O | _ | F | D | U | L | N | R | S | Y |\n",
    "\n",
    "\n",
    "Then `HELLO WORLD` would translate to `QMWWEYLEOWG`. Your job is to decode their message using the Metropolis-Hastings algorithm you wrote above. Our goal is to find the cipher that maximizes the likelihood of seeing the characters in the translated message. The cipher will be a list of integers representing the letter of the alphabet that the letter corresponding to that index should be translated to. For example, if \"g\" should be replaced with \"a\", then `cipher[6]` should equal `0`. **Note: 0-index when counting letters of the alphabet.**\n",
    "\n",
    "Our model of language will consider each character to be dependent only on the previous character. For example,\n",
    "\n",
    "$$\\mathbb{P}(x_1 = c, x_2 = a, x_3 = t) = \\mathbb{P}(x_1 = c)\\mathbb{P}(x_2 = a|x_1 = c)\\mathbb{P}(x_3 = t|x_2 = a)$$\n",
    "\n",
    "These transition probabilities will be calculated empirically by counting the number of transitions between every pair of characters in a large corpus of text.\n",
    "\n",
    "The state space is the set of all ciphers \n",
    "$$X = \\{\\sigma : \\sigma \\text{ is a permutation of the English alphabet and  ``\\_''}\\}.$$ \n",
    "$|X| = 27!$, so finding the most likely cipher is far too costly to calculate naively, but we can sample from the space of all ciphers intelligently by using Metropolis-Hastings with the following functions:\n",
    "\n",
    "**Proposals**: To propose new ciphers, we will randomly swap two characters in our cipher.\n",
    "\n",
    "**Acceptance Function**: Note that because our proposal distribution is symmetric, the acceptance probability becomes $A(x,y) = \\min\\{1, \\frac{f(y)}{f(x)}\\}$. \n",
    "$f(x)$ is the probability of observing the sequence of characters in the message decoded by cipher $x$: \n",
    "\n",
    "$$f(\\cdot) = \\mathbb{P}(x_1 = \\text{letter}_1)\\mathbb{P}(x_2 = \\text{letter}_2|x_1 = \\text{letter}_1)\\mathbb{P}(x_3 = \\text{letter}_3|x_2 = \\text{letter}_2)$$\n",
    "\n",
    "$f(\\cdot)$ is _not_ a valid probability over all ciphers because we don't normalize, but it is sufficient for us to compare two ciphers.\n",
    "\n",
    "Here is an example of one iteration of the algorithm. If we are dealing with a reduced alphabet of $\\{A,B,C,D,\\text{' '}\\}$ and our current cipher is $[ 2,0,4,3,1 ]$, then we are mapping $A->C, B->A, C->\\text{' '}$, etc. If our proposal function suggests the perturbed cipher $[ 4,0,2,3,1 ]$, we will accept this cipher as our new state with probability $\\min \\{1, \\frac{f([ 4,0,2,3,1 ])}{f([ 2,0,4,3,1 ])}\\}$.\n",
    "\n",
    "We wrote functions to find the bigram frequency matrix, which gives the transition probabilities between characters, and to convert messages into a numerical format. To run the starter code below, you will need to run following cell to download corpus from which we will learn the transition probabilities. This will save a file called `war_and_peace.txt` in the current directory.\n",
    "\n",
    "Some final notes and tips:\n",
    "- For simplicity's sake, don't worry about the initial $P(x_1 = \\text{letter}_1)$: the sequence is 538 characters long, so this initial probability won't affect the relative probability between 2 ciphers by any noticeable amount.\n",
    "- To translate from letters to numbers quickly, take a look at the built-in `ord` function. Keep in mind that we are only working with uppercase letters, so it will map each letter to an integer in the range 65 to 90.\n",
    "- For numerical stability, to find $\\frac{f(y)}{f(x)}$, compute $\\log(f(y)) - \\log(f(x))$, and then pass it to the exp function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Linux/MacOS\n",
    "! curl 'https://www.gutenberg.org/files/2600/2600-0.txt' > war_and_peace.txt\n",
    "the_secret_message=\"VTBALNDMNYBQQBSDWVQQUNO RT INVTBLDMNO VYG MNDMNOBNCDAWMGNOG NTWABRWOUNVAINGVO NOGBM NJGBNVR NIWEE R AONVAINDAWSD NVMNWTCBMOBRMNWAMO VINWNQWH NOG NXR VOGNBENER MGNVWRNOGWMNCRBXQ TNCRBZWI MNVMNVNA JNC RMC YOWZ NBANI IDYOWBANOGVONWMNABONR INWMNMDMNR INZ AO IN OYNOGVONGVMNX  ANIBTWAVOWALNOG NPBH MNBENTUNC  RMNVAINOG NZW JNBENTUNE  INU ONXUNORUWALNOBNEBRY NOGWMNCRBXQ TNOBNYBAEBRTNOBNVTBLDMNUBDNUBDRM QENVR NORUWALNOBNYRDMGNBRWLWAVQWOUNVAINDAWSD A MMNVTBALNDMNWMNVNLVT NDQOWTVO QUNYBAZWAYWALNDMNOBNYBAEBRTNOBNT AWVQNQVXBRNVMNOVMHMNVAINVYY CONOG NI VQNBENX WALNPDMONQWH NOG NR MONBENOG NYR JTVO M\"\n",
    "# On Windows download from https://www.gutenberg.org/files/2600/2600-0.txt\n",
    "# and save as war_and_peace.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = \"war_and_peace.txt\"\n",
    "\n",
    "def build_bigram_freq_matrix(input_file):\n",
    "    \"\"\"\n",
    "    Builds a matrix that represents the transitional\n",
    "    probabilities between letters in input_file.\n",
    "    \n",
    "    bigram_freq_matrix[0][1] is the probability of\n",
    "    transitioning from the 0th letter of the alphabet\n",
    "    to the 1st letter of the alphabet, where letters\n",
    "    are zero-indexed. ' ' (space) is denoted as the\n",
    "    26th letter of the alphabet.\n",
    "    \"\"\"\n",
    "    counts = np.ones([27, 27])\n",
    "    with open(input_file, 'r', encoding='utf8') as f:\n",
    "        for _ in range(100000):\n",
    "            line = f.readline()\n",
    "            if len(line) > 2:\n",
    "                for i in range(len(line) - 2):\n",
    "                    first_char = ord(line[i].upper()) - 65 if line[i].isalpha() else 26\n",
    "                    second_char = ord(line[i+1].upper()) - 65 if line[i+1].isalpha() else 26\n",
    "                    if not (first_char == 26 and second_char == 26) and first_char <= 26 and second_char <= 26:\n",
    "                        counts[first_char][second_char] += 1\n",
    "        bigram_freq_matrix = (counts.T / np.sum(counts, axis=1)).T\n",
    "    return bigram_freq_matrix\n",
    "\n",
    "def decode(string, ordering):\n",
    "    \"\"\"\n",
    "    Decodes a string according to the given\n",
    "    ordering.\n",
    "    \n",
    "    ordering: a list representing the cipher.\n",
    "        For example, if in our cipher, 'a'\n",
    "        should be replaced with 'c', then \n",
    "        ordering[0] should equal 2.\n",
    "    \"\"\"\n",
    "    output_str = \"\"\n",
    "    for i in string:\n",
    "        first_char = ord(i.upper()) - 65 if i.isalpha() else 26\n",
    "        output_str += chr(ordering[first_char] + 65) if ordering[first_char] != 26 else \" \"\n",
    "    return output_str\n",
    "\n",
    "bigram_freq_matrix = build_bigram_freq_matrix(input_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the Bigram Frequency Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(bigram_freq_matrix, cmap='binary', interpolation='none')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "def starting_state():\n",
    "    \"\"\"\n",
    "    Return a random permutation of indices representing the alphabet.\n",
    "    \"\"\"\n",
    "    ...\n",
    "\n",
    "assert len(starting_state()) == 27\n",
    "\n",
    "def sample_candidate(sample):\n",
    "    \"\"\"\n",
    "    To search for new ciphers, create a \n",
    "    new cipher from the old cipher with\n",
    "    two letters swapped.\n",
    "    \n",
    "    sample: previous cipher, list\n",
    "    \"\"\"\n",
    "    ...\n",
    "\n",
    "def make_log_f(decode_string, transition_matrix):\n",
    "    \"\"\"\n",
    "    Generates a function which computes the \n",
    "    log of the function f in the description \n",
    "    (the probability of observing the sequence \n",
    "    of characters in the message decoded by \n",
    "    cipher x), which is then used to calculate \n",
    "    acceptance probabilities.\n",
    "    \n",
    "    decode_string: secret message string\n",
    "    transition_matrix: matrix representing\n",
    "        transition probabilities from\n",
    "        char i to char j.\n",
    "    \"\"\"\n",
    "    def log_f(current_sample):\n",
    "        ...\n",
    "    return log_f\n",
    "\n",
    "def make_acceptance_scorer(log_f):\n",
    "    \"\"\"\n",
    "    Calculate the acceptance probability, which is the\n",
    "    probability of observing the message translated by\n",
    "    the proposed cipher devided by the probability of\n",
    "    observing the message translated by the current\n",
    "    cipher. See notes above about using log likelihood\n",
    "    for stability.\n",
    "    \n",
    "    log_f: function that computes the log of the probability\n",
    "        of observing the message translated by the current cipher\n",
    "    \"\"\"\n",
    "    def scorer(current_sample, candidate):\n",
    "        ...\n",
    "    return scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"implement_mcmc_decoding\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_f = make_log_f(the_secret_message, bigram_freq_matrix)\n",
    "scorer = make_acceptance_scorer(log_f)\n",
    "samples = metropolis_hastings(sample_candidate, starting_state, scorer, 8000, step=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Watch your Decoding Improve\n",
    "\n",
    "We print out the first few samples below. As you continue to sample from the space of all ciphers, the quality of your decoding should improve roughly. **You may have to run the algorithm a few times to achieve good results.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sample in samples[::len(samples) // 5]:\n",
    "    print(decode(the_secret_message, sample), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Let's Get Sleuthy (3 points)\n",
    "\n",
    "What did Gary's secret message to Tavor say?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "log_probs = [log_f(s) for s in samples]\n",
    "print(len(log_probs))\n",
    "best_cipher_index = np.argmax(log_probs)\n",
    "print(decode(the_secret_message, samples[best_cipher_index]).upper())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Do you recognize this secret message?\n",
    "\n",
    "You may notice that sometimes when you run the algorithm, certain letters are not decoded correctly. For example, \"crewmates\" may be translated as \"crexmates.\" In addition, the decoding may fail catastrophically, never yielding a intelligible message. Try to think about why this might be the case, and then answer the following questions.\n",
    "\n",
    "**Question 6:** Why might certain letters not be decoded correctly in the MCMC algorithm?\n",
    "- The MCMC algorithm only works for sampling random data, so it's not suited for decoding a fixed string with a deterministic mapping. \n",
    "- Some letters appear infrequently, making it difficult to distinguish between correct and incorrect mappings.\n",
    "- The English language doesn't have a consistent structure for letter frequencies.\n",
    "- The algorithm intentionally introduces errors to make the decoding more challenging.\n",
    "\n",
    "**Question 7:** Why might the decoding fail catastrophically and never yield an intelligible message? Choose the best answer:\n",
    "\n",
    "- Catastrophic failure is a sign that the original message was not in English.\n",
    "- If the initial cipher is poor, the algorithm might get stuck in a local optimum.\n",
    "- The MCMC algorithm has a fixed memory window, so it will fail for long messages.\n",
    "- Catastrophic failure only occurs when the number of iterations is too small.\n",
    "\n",
    "**Question 8:** What is the decoded message? Enter the letter corresponding to the correct message.\n",
    "    return the message that you decoded as a string, all uppercase, without any additional leading or trailing spaces, and with *no quotation marks*. \n",
    "    \n",
    "    For example, you might write `THIS IS A TEST MESSAGE`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission Instructions\n",
    "For this lab, there is **no** export cell. Instead, directly upload your completed `.ipynb` to the relevant Gradescope assignment. Make sure to save your work before uploading!!!\n",
    "\n",
    "Additionally, make sure all written questions have been answered in the corresponding Gradescope assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sources and Further Reading\n",
    "\n",
    "[1] https://people.eecs.berkeley.edu/~sinclair/cs294/n1.pdf\n",
    "\n",
    "[2] http://www.mit.edu/~ilkery/papers/MetropolisHastingsSampling.pdf\n",
    "\n",
    "[3] http://statweb.stanford.edu/~cgates/PERSI/papers/MCMCRev.pdf"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "eecs126",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "otter": {
   "OK_FORMAT": true,
   "tests": {
    "implement_mcmc_decoding": {
     "name": "implement_mcmc_decoding",
     "points": 4,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert sorted(starting_state()) == list(range(27)), 'Error: Starting state is not a permutation of the alphabet'\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> init = starting_state()\n>>> sample = sample_candidate(init)\n>>> assert sorted(sample) == list(range(27)), 'Error: Candidate state is not a permutation of the alphabet'\n>>> num_swaps = 0\n>>> for a, b in zip(init, sample):\n...     if a != b:\n...         num_swaps += 1\n>>> assert num_swaps == 2, 'Error: Candidate state is not the result of swapping two letters in the starting state, make sure you always swap two letters'\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> test_log_f = make_log_f('HELLO WORLD', bigram_freq_matrix)\n>>> ans = -25.432\n>>> assert np.abs(test_log_f(list(range(27))) - ans) < 0.1, 'Error: Log f is incorrect, make sure you only account for transitions between letters'\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> sample = list(range(27))\n>>> sample[4], sample[1] = (sample[1], sample[4])\n>>> test_log_f = make_log_f('HELLO WORLD', bigram_freq_matrix)\n>>> scorer = make_acceptance_scorer(test_log_f)\n>>> assert np.abs(scorer(list(range(27)), sample) * scorer(sample, list(range(27))) - 1) < 0.01, 'Error: Acceptance scorer is incorrect'\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "metropolis_hastings_implementation": {
     "name": "metropolis_hastings_implementation",
     "points": 3,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> sample_prior = lambda: np.random.normal(loc=2)\n>>> sample_candidate = lambda theta: np.random.normal(loc=theta)\n>>> scorer = lambda x, y: math.exp(-(y - 1) ** 2 / 2) / math.exp(-(x - 1) ** 2 / 2)\n>>> normal_samples = metropolis_hastings(sample_candidate, sample_prior, scorer, 300)\n>>> assert len(normal_samples) == 10, 'Number of samples is incorrect, you should return num_iters // step samples'\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> import scipy.stats as stats\n>>> max_p = 0\n>>> correct = False\n>>> sample_prior = lambda: np.random.normal(loc=50)\n>>> sample_candidate = lambda theta: np.random.normal(loc=theta)\n>>> scorer = lambda x, y: math.exp(-(y - 60) ** 2 / 2) / math.exp(-(x - 60) ** 2 / 2)\n>>> normal_samples = metropolis_hastings(sample_candidate, sample_prior, scorer, 3000)\n>>> for _ in range(4):\n...     normal_samples = metropolis_hastings(sample_candidate, sample_prior, scorer, 3000)\n...     stat, p_value = stats.kstest(normal_samples, 'norm', args=(60, 1))\n...     if p_value > 0.05:\n...         correct = True\n...         break\n>>> assert correct, 'KS test failed for normal distribution, this indicates your implementation is incorrect'\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> import scipy.stats as stats\n>>> max_p = 0\n>>> correct = False\n>>> sample_prior = lambda: 9\n>>> sample_candidate = lambda theta: np.random.normal(loc=theta)\n>>> exp_pdf = exponential(1.5)\n>>> exp_scorer = lambda x, y: exp_pdf(y) / exp_pdf(x)\n>>> correct = False\n>>> for _ in range(4):\n...     exp_samples = metropolis_hastings(sample_candidate, sample_prior, exp_scorer, 6000)\n...     stat, p_value = stats.kstest(exp_samples, 'expon', args=(0, 1 / 1.5))\n...     if p_value > 0.05:\n...         correct = True\n...         break\n>>> assert correct, 'KS test failed for exponential distribution, this indicates your implementation is incorrect'\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
